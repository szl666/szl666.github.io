name: Get Citation Data

on: 
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch: # 允许手动触发

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 10 # 减少到10分钟
    steps:
    - uses: actions/checkout@v4 # 更新到最新版本
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        cd ./google_scholar_crawler
        pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run crawler with retry
      run: |
        cd ./google_scholar_crawler
        # 添加重试机制
        for i in {1..3}; do
          echo "尝试第 $i 次..."
          if python3 main.py; then
            echo "成功获取数据"
            break
          else
            echo "第 $i 次失败，等待30秒后重试..."
            sleep 30
          fi
          if [ $i -eq 3 ]; then
            echo "所有尝试都失败了"
            exit 1
          fi
        done
        
    - name: Commit and push changes
      run: |
        cd ./google_scholar_crawler/results
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add *.json
        if git diff --staged --quiet; then
          echo "没有变化，跳过提交"
        else
          git commit -m "Updated Citation Data - $(date '+%Y-%m-%d %H:%M:%S')"
          git push origin HEAD:google-scholar-stats --force
        fi
      env: 
        GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
